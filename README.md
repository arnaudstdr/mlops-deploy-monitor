# ğŸš´â€â™‚ï¸ API de PrÃ©diction de Calories

[![CI - Build and Test FastAPI App](https://github.com/arnaudstdr/mlops-deploy-monitor/actions/workflows/deploy.yml/badge.svg)](https://github.com/arnaudstdr/mlops-deploy-monitor/actions/workflows/deploy.yml)
[![Deploy on Render](https://render.com/images/deploy-to-render-button.svg)](https://render.com/deploy)

API FastAPI pour prÃ©dire les **calories brÃ»lÃ©es lors dâ€™une sortie Ã  vÃ©lo** Ã  partir de donnÃ©es physiologiques et de performance.  
DÃ©veloppÃ©e dans une logique **MLOps** avec conteneurisation, CI/CD et tests automatisÃ©s.

## âœ¨ FonctionnalitÃ©s

- ğŸ”® PrÃ©diction des calories brÃ»lÃ©es avec un modÃ¨le Scikit-learn
- ğŸš€ API RESTful avec FastAPI
- ğŸ§ª Tests utnitaires et automatisÃ©s avec `pytest` et `httpx`
- ğŸ³ Dockerisation complÃ¨te
- ğŸ” CI/CD avec GitHub Actions
- ğŸ“œ Documentation automatique (Swagger)

## ğŸ“¦ Installation locale

### 1. Clone du repo
```bash
git clone https://github.com/arnaudstdr/mlops-deploy-monitor.git
cd mlops-deploy-monitor
```

### 2. Build de l'image Docker
```bash
docker build -t mlops-api .
```

### 3. Lancement du conteneur
```bash
docker run -d -p 8000:8000 mlops-api
```
â¡ï¸ L'API est disponible sur : http://localhost:8000/docs

## ğŸ³ Utilisation avec Dev Container

Ce projet est prÃªt Ã  Ãªtre utilisÃ© avec [Dev Containers](https://containers.dev/) de VS Code.

### 1. Ouvrir dans VS Code
- Installez l'extension **Dev Containers** sur VS Code.
- Ouvrez le dossier du projet dans VS Code.
- Cliquez sur `Reopen in Container` lorsque cela est proposÃ©, ou utilisez la palette de commandes (`F1`) :
  - `Dev Containers: Reopen in Container`

L'environnement de dÃ©veloppement (Python, dÃ©pendances, outils) sera automatiquement configurÃ© dans le conteneur.

â¡ï¸ Vous pouvez ensuite lancer l'API, exÃ©cuter les tests, etc. directement dans le conteneur.

## ğŸ”Œ Endpoints
| MÃ©thode | Endpoint   | Description                  |
|---------|------------|------------------------------|
| POST    | `/predict` | PrÃ©dire les calories brÃ»lÃ©es |
| GET     | `/health`  | VÃ©rifier l'Ã©tat de l'API     |

ğŸ“˜ AccÃ¨s complet Ã  la documentation Swagger : http://localhost:8000/docs

ğŸŒ API dÃ©ployÃ©e en ligne : [https://mlops-deploy-monitor.onrender.com](https://mlops-deploy-monitor.onrender.com/docs)

## ğŸ“Š Suivi des expÃ©riences avec MLflow

Ce projet utilise [MLflow](https://mlflow.org/) pour le suivi des expÃ©riences de machine learning :
- Enregistrement automatique des paramÃ¨tres du modÃ¨le (type, hyperparamÃ¨tres)
- Suivi des mÃ©triques d'Ã©valuation (MAE, RMSE)
- Sauvegarde et versionning du modÃ¨le entraÃ®nÃ©
- Exemple d'entrÃ©e pour la reproductibilitÃ©

L'entraÃ®nement (`model/train.py`) logue chaque run dans MLflow. Vous pouvez visualiser l'historique des expÃ©riences et comparer les modÃ¨les via l'interface web MLflow.

### Lancer l'UI MLflow en local
```bash
mlflow ui --backend-store-uri mlruns
```
L'interface sera accessible sur : http://localhost:5000

> **Astuce :** Les artefacts et mÃ©triques sont stockÃ©s dans le dossier `mlruns/` Ã  la racine du projet.

## ğŸ§ª Tests

### Lancer les tests manuellement
```bash
pytest
```

### Tests intÃ©grÃ©s Ã  la CI GitHub
- âœ… VÃ©rification de l'infÃ©rence
- âœ… Format de la rÃ©ponse
- âœ… Gestion d'erreurs
- âœ… Valeurs extrÃªmes
- âœ… Temps de rÃ©ponse

## ğŸ³ Dockerfile
Le `Dockerfile` construit une image multi-stage :
1. **Stage builder**
   - CrÃ©ation d'un environnement virtuel
   - Installation des dÃ©pendances Python
2. **Stage fianl**
   - Copie du code + environnement
   - DÃ©marrage avec unicorn

## â˜¸ï¸ DÃ©ploiement sur Kubernetes

Kubernetes est un standard pour l'orchestration et le dÃ©ploiement de services en production dans le MLOps.

Un exemple complet de manifeste Kubernetes (`deployment.yaml`) est fourni Ã  la racine du projet. Ce fichier montre ma capacitÃ© Ã  industrialiser le dÃ©ploiement d'une API de machine learning dans un cluster cloud-native.

### 1. Fichier `deployment.yaml`
Le fichier contientâ€¯:
- Un objet **Deployment** pour dÃ©ployer et gÃ©rer la montÃ©e en charge de l'API
- Un objet **Service** pour exposer l'API sur le rÃ©seau du cluster

Vous pouvez l'adapter facilement Ã  votre image Docker (remplacez `<votre-image-docker>` par le nom de votre image, exâ€¯: `arnaudstdr/mlops-api:latest`).

### 2. DÃ©ploiement sur le cluster
```bash
kubectl apply -f deployment.yaml
```
L'API sera accessible sur le port 30080 du nÅ“ud (ou via un Ingress en production).

> Fournir ce fichier prouve la maÃ®trise des bonnes pratiques DevOps/MLOps et facilite l'intÃ©gration dans des environnements cloud ou hybrides.

Kubernetes permet de passer Ã  l'Ã©chelle, de monitorer et de gÃ©rer les dÃ©ploiements de modÃ¨les de faÃ§on industrielle.

## ğŸ›£ï¸ Roadmap
- âœ… Tests API
- âœ… CI/CD avec GitHub Actions
- âœ… Dockerisation
- âœ… Ajouter tracking dans `train.py` - MLflow (local)
- âœ… DÃ©ploiement sur Render
- âœ… Ajout d'un test direct du modÃ¨le (`test_model.py`)
- âœ… Monitoring simple (logs, latence)

## ğŸ§  Auteur
ğŸ‘¤ Arnaud STADLER - MLOps en reconversion passionnÃ© de data, de vÃ©lo et d'IA ğŸš´â€â™‚ï¸ğŸ§ 

## ğŸ“„ Licence
Ce projet est open-source sous licence [MIT](LICENSE). Vous pouvez l'utiliser, le modifier et le redistribuer librement dans le respect de cette licence.
